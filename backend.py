import os
import json
import asyncio
from contextlib import asynccontextmanager, AsyncExitStack
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware # å¯¼å…¥ CORS
from pydantic import BaseModel
from openai import OpenAI
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from dotenv import load_dotenv

# === é…ç½® ===
# Load environment variables from a .env file (if present) and from the environment.
load_dotenv()

# Try a few common environment variable names for the API key to be flexible.
API_KEY = os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENAI_API_KEY") or os.getenv("API_KEY")
BASE_URL = os.getenv("BASE_URL", "https://api.deepseek.com")
MODEL_NAME = os.getenv("MODEL_NAME", "deepseek-chat")

if not API_KEY or API_KEY in ("", "sk-", "your-api-key-here"):
    raise RuntimeError(
        "API key not set. Please add your API key to network-mcp/.env (DEEPSEEK_API_KEY) or set the environment variable."
    )

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

mcp_session = None
mcp_exit_stack = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global mcp_session, mcp_exit_stack
    server_params = StdioServerParameters(
        command="python",
        args=["mcp_tool.py"], 
        env=os.environ
    )
    mcp_exit_stack = AsyncExitStack()
    try:
        read, write = await mcp_exit_stack.enter_async_context(stdio_client(server_params))
        mcp_session = await mcp_exit_stack.enter_async_context(ClientSession(read, write))
        await mcp_session.initialize()
        print("âœ… Backend å·²è¿æ¥åˆ° MCP Search Server")
        yield
    finally:
        print("ğŸ›‘ æ­£åœ¨å…³é—­ MCP è¿æ¥...")
        await mcp_exit_stack.aclose()

app = FastAPI(lifespan=lifespan)

# ==========================================
# âœ… ä¿®å¤ CORS é—®é¢˜
# ==========================================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # å…è®¸ä»»ä½•å‰ç«¯è®¿é—®
    allow_credentials=True,
    allow_methods=["*"], # å…è®¸ GET, POST, OPTIONS
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str
    history: list = []

@app.post("/chat")
async def chat_endpoint(req: ChatRequest):
    if not mcp_session:
        raise HTTPException(status_code=500, detail="MCP Server æœªè¿æ¥")

    try:
        tools_list = await mcp_session.list_tools()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {str(e)}")

    openai_tools = [{
        "type": "function",
        "function": {
            "name": t.name,
            "description": t.description,
            "parameters": t.inputSchema
        }
    } for t in tools_list.tools]

    messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè”ç½‘åŠ©æ‰‹ã€‚è¯·å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"}]
    messages.append({"role": "user", "content": req.message})

    print(f"æ”¶åˆ°ç”¨æˆ·è¯·æ±‚: {req.message}")

    for i in range(5):
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                tools=openai_tools,
                tool_choice="auto"
            )
        except Exception as e:
            return {"response": f"æ¨¡å‹è°ƒç”¨å‡ºé”™: {e}"}
        
        msg = response.choices[0].message
        
        if not msg.tool_calls:
            return {"response": msg.content}
        
        messages.append(msg)
        
        for tool_call in msg.tool_calls:
            fn_name = tool_call.function.name
            fn_args = json.loads(tool_call.function.arguments)
            print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {fn_name}")
            
            try:
                result = await mcp_session.call_tool(fn_name, arguments=fn_args)
                tool_content = result.content[0].text
            except Exception as e:
                tool_content = f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
                print(f"ğŸ“„ [æœç´¢ç»“æœå†…å®¹ preview]: {tool_content[:100]}...")
            
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "name": fn_name,
                "content": tool_content
            })
            
    return {"response": "æ€è€ƒè¶…æ—¶æˆ–æ­¥éª¤è¿‡å¤š"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)